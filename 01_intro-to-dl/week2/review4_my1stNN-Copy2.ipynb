{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd part: Deep Learning applied on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# finish possible remaining session\n",
    "sess.close()\n",
    "\n",
    "#Start interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2214540f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "# train, validation and test X image 28x28 Y answear\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[2], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 28 # width of the image in pixels \n",
    "height = 28 # height of the image in pixels\n",
    "flat = width * height # number of pixels in one image \n",
    "class_output = 10 # number of possible classifications for the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = tf.placeholder(tf.float32, shape=[None, flat])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, class_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting images of the data set to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])  \n",
    "x_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolve1= tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(convolve1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\n",
    "conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First layer completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer 2\n",
    "#### Weights and Biases of kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #need 64 biases for 64 outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolve image with weight tensor and add biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolve2= tf.nn.conv2d(conv1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')+ b_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the ReLU activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv2 = tf.nn.relu(convolve2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_1:0' shape=(?, 7, 7, 64) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\n",
    "conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer\n",
    "\n",
    "#### Flattening Second Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2_matrix = tf.reshape(conv2, [-1, 7*7*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and Biases between layer 2 and 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024])) # need 1024 biases for 1024 outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication (applying weights and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcl=tf.matmul(layer2_matrix, W_fc1) + b_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the ReLU activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_fc1 = tf.nn.relu(fcl)\n",
    "h_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third layer completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Layer, Optional phase for reducing overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout/mul:0' shape=(?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "layer_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "layer_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Readout Layer (Softmax Layer)\n",
    "\n",
    "    \n",
    "#### Weights and Biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1)) #1024 neurons\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10])) # 10 possibilities for digits [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication (applying weights and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc=tf.matmul(layer_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the Softmax activation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_CNN= tf.nn.softmax(fc)\n",
    "y_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_CNN), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_CNN,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run session, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you want a fast result (**it might take sometime to train it**)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1)\n",
    "print(X_train_flatten.shape, X_test_flatten.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPS own external code\n",
    "# convert to one-hot encooding\n",
    "import numpy as np\n",
    "y_train = np.eye(class_output)[y_train]\n",
    "y_test = np.eye(class_output)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.11\n",
      "step 0, test accuracy 0.11\n",
      "step 100, training accuracy 0.94\n",
      "step 100, test accuracy 0.71\n",
      "step 200, training accuracy 1\n",
      "step 200, test accuracy 0.8\n",
      "step 300, training accuracy 1\n",
      "step 300, test accuracy 0.84\n",
      "step 400, training accuracy 0.98\n",
      "step 400, test accuracy 0.8\n",
      "step 500, training accuracy 1\n",
      "step 500, test accuracy 0.79\n",
      "step 600, training accuracy 0.99\n",
      "step 600, test accuracy 0.91\n",
      "step 700, training accuracy 1\n",
      "step 700, test accuracy 0.87\n",
      "step 800, training accuracy 1\n",
      "step 800, test accuracy 0.92\n",
      "step 900, training accuracy 1\n",
      "step 900, test accuracy 0.85\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    batch_size = 100\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:X_train_flatten[i:i+batch_size], y_:y_train[i:i+batch_size], keep_prob: 1.0})\n",
    "        test_accuracy = accuracy.eval(feed_dict={\n",
    "            x:X_test_flatten[i:i+batch_size], y_: y_test[i:i+batch_size], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        print(\"step %d, test accuracy %g\"%(i, test_accuracy))\n",
    "    train_step.run(feed_dict={x:X_train_flatten[i:i+batch_size], y_: y_train[i: i+batch_size], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "Print the evaluation to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9101\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: X_test_flatten, y_: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
